{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Notebook for the creation of mdtraj obtained data plots and PCA/tICA analysis\n",
    "\n",
    "\n",
    "- First you need to import the important libraries. Maybe you need to add more libraries. Feel free to add them in this first cell\n",
    "- Then you can load the functions that will be used later on. Nice_PES ia a function for plotting FEL plots in a nice way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful stuff\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import os\n",
    "import mdtraj as md\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import pandas as pd\n",
    "import pytraj as pt\n",
    "import glob\n",
    "\n",
    "# PyEmma\n",
    "import pyemma\n",
    "import pyemma.msm as msm\n",
    "import pyemma.plots as mpl\n",
    "import pyemma.coordinates as coor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FEL_RES_PYMOL(FEL, file_name):\n",
    "    a = 0\n",
    "    b = 1\n",
    "    color1 = input('Enter a color for PC0:')\n",
    "    color2 = input('Enter a color for PC1:')\n",
    "    with open(file_name, 'w') as f:    \n",
    "        dist_PCA_correl = FEL.feature_PC_correlation\n",
    "        for ii, icorr in enumerate(dist_PCA_correl.T):\n",
    "            if ii == a:\n",
    "                print(\"For PCA %u\"%ii)\n",
    "                argmaxs = [ii for ii in np.abs(icorr).argsort()[::-1] if not np.isnan(icorr[ii])]\n",
    "                for art in argmaxs[:10]:\n",
    "                    print('color ', color1,', resi', (feats[0].describe()[art][9:12]))\n",
    "                    f.write(pca)\n",
    "            if ii == b:\n",
    "                print(\"For PCA %u\"%ii)\n",
    "                argmaxs = [ii for ii in np.abs(icorr).argsort()[::-1] if not np.isnan(icorr[ii])]\n",
    "                for art in argmaxs[:10]:\n",
    "                    print('color ', color2,', resi', (feats[0].describe()[art][9:12]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_Nice_PES(P_test,bins=90,sigma=0.99, title=False, size = 1):\n",
    "\n",
    "    mpl.style.use(\"seaborn-paper\")\n",
    "    plt.figure(figsize=(6*size,5*size))\n",
    "    alldata=np.vstack(P_test)\n",
    "    min1=np.min(alldata[:,0])\n",
    "    max1=np.max(alldata[:,0])\n",
    "    min2=np.min(alldata[:,1])\n",
    "    max2=np.max(alldata[:,1])\n",
    "    \n",
    "    tickspacing1=1.0\n",
    "    tickspacing2=1.0\n",
    "    z,x,y = np.histogram2d(alldata[:,0], alldata[:,1], bins=bins)\n",
    "    z += 0.1\n",
    "    \n",
    "    # compute free energies\n",
    "    F = -np.log(z)\n",
    "    \n",
    "    \n",
    "    # contour plot\n",
    "    extent = [x[0], x[-1], y[0], y[-1]]\n",
    "    \n",
    "    plt.xticks(np.arange(int(min1), int(max1)+1, tickspacing1),fontsize=10*size)\n",
    "    plt.yticks(np.arange(int(min2), int(max2)+1, tickspacing2),fontsize=10*size)\n",
    "    #    sigma = 0.99 # this depends on how noisy your data is, play with it!\n",
    "    data = gaussian_filter((F.T)*0.592-np.min(F.T)*0.592, sigma)\n",
    "    levels=np.linspace(0,np.max(data)-0.5,num=10)\n",
    "    plt.contour(data,colors='black',linestyles='solid',alpha=0.7,cmap=None, cbar=True, levels=levels,extent=extent)\n",
    "    plt.contourf(data,alpha=0.5,cmap='jet', cbar=True,levels=levels,extent=extent)\n",
    "    if title:\n",
    "        plt.title(title, fontsize = 20*size, y=1.02)\n",
    "    plt.subplots_adjust(bottom=0.1, right=0.8, top=0.8)\n",
    "    cax = plt.axes([0.81, 0.1, 0.02, 0.7])\n",
    "    plt.colorbar(cax=cax, format='%.1f').set_label('Free energy (kcal/mol)', fontsize=10*size, labelpad=5, y= 0.5)\n",
    "    cax.axes.tick_params(labelsize=10*size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "#import nglview as nv\n",
    "import ipywidgets as widgets\n",
    "import pytraj as pt\n",
    "import warnings\n",
    "import tqdm\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%pylab inline\n",
    "%matplotlib inline\n",
    "\n",
    "def interactive_FEL2(TICA_test, trajfiles, topfile, output_plot=True, n_frames=1,output_structure=False, size=1, bins=90, sigma=0.99, pc1=0, pc2=1):\n",
    "    '''\n",
    "        \n",
    "        Plot the Free Energy Surface(FES) of the given data in a matplotlib pyqt. User can select a point in the FES. \n",
    "        \n",
    "                \n",
    "        If you experience some problem or you have any comment with this function --> https://github.com/miqueleg/compbiolab :3\n",
    "        \n",
    "        Parameters: ---------------------------------------------------------------------------------\n",
    "        \n",
    "        data: 3D ndarray (MD,frames,tic_dim). If not, the calculations will be wrong!!\n",
    "        \n",
    "        trajfiles: 1D array containing all trajectories strings containing files path and name(order in the list is important)\n",
    "        \n",
    "        topfile: string containing file path and name for the .pdb file that will be used as topology.\n",
    "        \n",
    "        output_plot: If true, a plot including the FES and selected pint will be displayed at the end.\n",
    "            default=True\n",
    "            \n",
    "        output_structure: If True,the selected structure is also returned as pytraj structure.\n",
    "            default=False\n",
    "            \n",
    "        size: Float/Integer that defines the size of the plots\n",
    "            default=1\n",
    "            \n",
    "        \n",
    "        Returns: -------------------------------------------------------------------------------------------\n",
    "        \n",
    "        - nglview of the structure selected\n",
    "        \n",
    "        - If output_structure=True, the selected structure is also returned as pytraj structure\n",
    "        \n",
    "        Only in in jupyter-notebook\n",
    "          \n",
    "    '''\n",
    "    ##This imports are kind of necessary in order to plot the graphic in the Tk canvas(PQt5).\n",
    "    ## At the end of the function, the matplotlib inline canvas has to be setted again in order to do not disturbe next plots\n",
    "    %matplotlib qt\n",
    "\n",
    "    ##Plot the Free energy surface as Nice_PES function\n",
    "    mpl.style.use(\"seaborn-paper\")\n",
    "    fig, ax = plt.subplots(figsize=(6*size,5*size))\n",
    "    alldata=np.vstack(TICA_test)\n",
    "    min1=np.min(alldata[:,pc1])\n",
    "    max1=np.max(alldata[:,pc1])\n",
    "    min2=np.min(alldata[:,pc2])\n",
    "    max2=np.max(alldata[:,pc2])\n",
    "    print(all_data.shape)\n",
    "\n",
    "    tickspacing1=1.0\n",
    "    tickspacing2=1.0\n",
    "    z,x,y = np.histogram2d(alldata[:,pc1], alldata[:,pc2], bins=bins)\n",
    "    z += 0.1\n",
    "\n",
    "    # compute free energies\n",
    "    F = -np.log(z)\n",
    "\n",
    "    # contour plot\n",
    "    extent = [x[0], x[-1], y[0], y[-1]]\n",
    "\n",
    "    plt.xticks(np.arange(int(min1), int(max1)+1, tickspacing1),fontsize=10*size)\n",
    "    plt.yticks(np.arange(int(min2), int(max2)+1, tickspacing2),fontsize=10*size)\n",
    "    #    sigma = 0.99 # this depends on how noisy your data is, play with it!\n",
    "    data = gaussian_filter((F.T)*0.592-np.min(F.T)*0.592, sigma)\n",
    "    levels=np.linspace(0,np.max(data)-0.5,num=8)\n",
    "    ax.contour(data,colors='black',linestyles='solid',alpha=0.7,cmap=None, cbar=True, levels=levels,extent=extent)\n",
    "    ax.contourf(data,alpha=0.5,cmap='jet', cbar=True,levels=levels,extent=extent)\n",
    "\n",
    "    ##ginput will wait until a click is done into the plot and collect the coordinates into the x variable\n",
    "    x = plt.ginput()\n",
    "\n",
    "\n",
    "    #nodes are the prepared data corresponding of the points on the TICA scatter (tic0 and tic1 by default)\n",
    "    nodes = np.array(list(zip(alldata[:,pc1],alldata[:,pc2])))\n",
    "    node = np.array(x[0])\n",
    "    #cdist finction computes the distance matrix between TICA nodes and node\n",
    "    distances = np.array(cdist([node], nodes))\n",
    "    #clicked frame is the position in the matrix distance in wich you can find the minimun value\n",
    "    clicked_frames = np.argsort(distances)[0]\n",
    "    clicked_frames = clicked_frames[:n_frames]\n",
    "    MD_out = pt.Trajectory(top=topfile)\n",
    "    \n",
    "    for f in tqdm.tqdm(range(len(clicked_frames))):\n",
    "        clicked_frame = clicked_frames[f]\n",
    "        MD=pt.iterload(trajfiles, top=topfile)\n",
    "        MD_out.append(MD[clicked_frame])\n",
    "\n",
    "        #Frames is a list containing the len of all the MD's.\n",
    "        #This forces the input TICA_test to have a 3D shape (MD,frames,tic_dim). If not, the calculations are wrong!!\n",
    "        Frames = []\n",
    "        for traj in TICA_test:\n",
    "            Frames.append(len(traj))\n",
    "        #In this loop is computed in wich MD and MD_frame you can find the clicked frame\n",
    "        MD = 0\n",
    "        Frame = clicked_frame\n",
    "        for i in list(range(len(Frames))):\n",
    "            sum_frames = sum([Frames[j] for j in list(range(len(Frames))) if j <= i])\n",
    "            if clicked_frame <= sum_frames:\n",
    "                MD = i\n",
    "                Frame = clicked_frame - sum([Frames[j] for j in list(range(len(Frames))) if j < i])\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "    #The selected_frame is displayed using pytraj and nglview\n",
    "    MD=pt.iterload(trajfiles, top=topfile)\n",
    "    view=nv.show_pytraj(MD)\n",
    "    view.clear()\n",
    "    view.add_cartoon(selection=\"protein\")\n",
    "    view.frame = int(clicked_frame)\n",
    "\n",
    "    #returning to the matplotlib inline\n",
    "    %matplotlib inline\n",
    "    #plot the selected position with a scatter\n",
    "    if output_plot:\n",
    "        plt.figure(figsize=(6*size,5*size))\n",
    "        plt.contour(data,colors='black',linestyles='solid',alpha=0.7,cmap=None, cbar=True, levels=levels,extent=extent)\n",
    "        plt.contourf(data,alpha=0.2,cmap='jet', cbar=True,levels=levels,extent=extent)\n",
    "        plt.scatter(np.array(x)[:,0],np.array(x)[:,1], c ='b', s =50)\n",
    "    if output_structure:\n",
    "        return view, MD_out\n",
    "    else:\n",
    "        return view\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Discretization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I start by defining the input files names and the input coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### APO variants ####\n",
    "\n",
    "directo= \n",
    "trajfiles_HG3_apo=[fi for fi in glob.glob(directo + '*_super.dcd')]\n",
    "topfile_HG3_apo=\n",
    "\n",
    "directo=\n",
    "trajfiles_HG317_apo=[fi for fi in glob.glob(directo + '*_super.dcd')]\n",
    "topfile_HG317_apo=\n",
    "\n",
    "directo=\n",
    "trajfiles_HG317_shell_apo=[fi for fi in glob.glob(directo + '*_super.dcd')]\n",
    "topfile_HG317_shell_apo=\n",
    "\n",
    "directo=\n",
    "trajfiles_HG4_apo=[fi for fi in glob.glob(directo + '*_super.dcd')]\n",
    "topfile_HG4_apo=\n",
    "\n",
    "\n",
    "##### TS variants ####\n",
    "\n",
    "directo=\n",
    "trajfiles_HG3_ts=[fi for fi in glob.glob(directo + '*_super.dcd')]\n",
    "topfile_HG3_ts=\n",
    "\n",
    "directo=\n",
    "trajfiles_HG317_ts=[fi for fi in glob.glob(directo + '*_super.dcd')]\n",
    "topfile_HG317_ts=\n",
    "\n",
    "directo=\n",
    "trajfiles_HG317shell_ts=[fi for fi in glob.glob(directo + '*_super.dcd')]\n",
    "topfile_HG317shell_ts=\n",
    "\n",
    "directo=\n",
    "trajfiles_HG4_ts=[fi for fi in glob.glob(directo + '*_super.dcd')]\n",
    "topfile_HG4_ts=\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajfiles_GCV_ATP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajfiles = []\n",
    "trajfiles.append(trajfiles_HG3_apo)\n",
    "trajfiles.append(trajfiles_HG317_apo)\n",
    "trajfiles.append(trajfiles_HG317shell_apo)\n",
    "trajfiles.append(trajfiles_HG4_apo)\n",
    "trajfiles.append(trajfiles_HG3_ts)\n",
    "trajfiles.append(trajfiles_HG317_ts)\n",
    "trajfiles.append(trajfiles_HG317shell_ts)\n",
    "trajfiles.append(trajfiles_HG4_ts)\n",
    "\n",
    "\n",
    "topfiles = []\n",
    "topfiles.append(topfile_HG3_apo)\n",
    "topfiles.append(topfile_HG317_apo)\n",
    "topfiles.append(topfile_HG317shell_apo)\n",
    "topfiles.append(topfile_HG4_apo)\n",
    "topfiles.append(topfile_HG3_ts)\n",
    "topfiles.append(topfile_HG317_ts)\n",
    "topfiles.append(topfile_HG317shell_ts)\n",
    "topfiles.append(topfile_HG4_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topfiles"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We normaly organize the data as the following: \n",
    "- FEATS are the lists variables that contains the data that will be used to extract info from the MD's (only based in the topfile). Feats list contain the feats for all systems. ej: feat1 == feats[0]\n",
    "- SOURCES are the arrays containing the values of the feats for all frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA / TICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat1=pyemma.coordinates.featurizer(topfiles[0])\n",
    "all_Ca1=feat1.select_Ca() # Features selected CA coordinates. The trajectories MUST be aligned first!\n",
    "print(all_Ca1)            # if you want to avoid the aligning, you can use: feat1.add_distances_ca()\n",
    "feat1.add_selection(all_Ca1)\n",
    "\n",
    "feat2=pyemma.coordinates.featurizer(topfiles[1])\n",
    "all_Ca2=feat2.select_Ca()\n",
    "print(all_Ca2)\n",
    "feat2.add_selection(all_Ca2)\n",
    "\n",
    "feat3=pyemma.coordinates.featurizer(topfiles[2])\n",
    "all_Ca3=feat3.select_Ca()\n",
    "print(all_Ca3)\n",
    "feat3.add_selection(all_Ca3)\n",
    "\n",
    "feat4=pyemma.coordinates.featurizer(topfiles[3])\n",
    "all_Ca4=feat4.select_Ca()\n",
    "print(all_Ca4)\n",
    "feat4.add_selection(all_Ca4)\n",
    "\n",
    "feat5=pyemma.coordinates.featurizer(topfiles[4])\n",
    "all_Ca5=feat5.select_Ca()\n",
    "print(all_Ca5)\n",
    "feat5.add_selection(all_Ca5)\n",
    "\n",
    "feat6=pyemma.coordinates.featurizer(topfiles[5])\n",
    "all_Ca6=feat6.select_Ca()\n",
    "print(all_Ca6)\n",
    "feat6.add_selection(all_Ca6)\n",
    "\n",
    "feat7=pyemma.coordinates.featurizer(topfiles[6])\n",
    "all_Ca7=feat7.select_Ca()\n",
    "print(all_Ca7)\n",
    "feat7.add_selection(all_Ca7)\n",
    "\n",
    "feat8=pyemma.coordinates.featurizer(topfiles[7])\n",
    "all_Ca8=feat8.select_Ca()\n",
    "print(all_Ca8)\n",
    "feat8.add_selection(all_Ca8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(feat1.describe()))\n",
    "print(len(feat2.describe()))\n",
    "print(len(feat3.describe()))\n",
    "print(len(feat4.describe()))\n",
    "print(len(feat5.describe()))\n",
    "print(len(feat6.describe()))\n",
    "print(len(feat7.describe()))\n",
    "print(len(feat8.describe()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats=[]\n",
    "feats.append(feat1)\n",
    "feats.append(feat2)\n",
    "feats.append(feat3)\n",
    "feats.append(feat4)\n",
    "feats.append(feat5)\n",
    "feats.append(feat6)\n",
    "feats.append(feat7)\n",
    "feats.append(feat8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This may take a while\n",
    "\n",
    "sources=[]\n",
    "print (len(feats[0].describe()))\n",
    "for traj in range(0,len(topfiles)):\n",
    "    print (traj,len(trajfiles))\n",
    "    sources.append(pyemma.coordinates.load(trajfiles[traj],features=feats[traj]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(sources).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_data = sources[0] + sources[1] + sources[2] + sources[3] + sources[4] + sources[5] + sources[6] + sources[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "\n",
    "- Here the PCA space is created using all the data from all the systems. This can be done if we have the same features for all the different systems.\n",
    "- Later on, the data is splitted for the different systems, but the space is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_joint=pyemma.coordinates.pca(data=joint_data,kinetic_map=False,stride=1)\n",
    "pca_Y = pca_joint.get_output()\n",
    "pca_HG3_apo,pca_HG317_apo, pca_HG317shell_apo,pca_HG4_apo, pca_HG3_ts,pca_HG317_ts, pca_HG317shell_ts,pca_HG4_ts, = np.split(pca_Y, np.cumsum(list(map(len, trajfiles)))[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data=np.vstack(pca_Y)\n",
    "pyemma.plots.plot_free_energy(all_data[:,0], all_data[:,1], avoid_zero_count=1)\n",
    "extend=axis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data=np.vstack(pca_HG3_apo)\n",
    "pyemma.plots.plot_free_energy(all_data[:,0], all_data[:,1], avoid_zero_count=1)\n",
    "axis(extend)\n",
    "\n",
    "all_data=np.vstack(pca_HG317_apo)\n",
    "pyemma.plots.plot_free_energy(all_data[:,0], all_data[:,1], avoid_zero_count=1)\n",
    "axis(extend)\n",
    "\n",
    "all_data=np.vstack(pca_HG317shell_apo)\n",
    "pyemma.plots.plot_free_energy(all_data[:,0], all_data[:,1], avoid_zero_count=1)\n",
    "axis(extend)\n",
    "\n",
    "all_data=np.vstack(pca_HG_4apo)\n",
    "pyemma.plots.plot_free_energy(all_data[:,0], all_data[:,1], avoid_zero_count=1)\n",
    "axis(extend)\n",
    "\n",
    "all_data=np.vstack(pca_HG3_ts)\n",
    "pyemma.plots.plot_free_energy(all_data[:,0], all_data[:,1], avoid_zero_count=1)\n",
    "axis(extend)\n",
    "\n",
    "all_data=np.vstack(pca_HG317_ts)\n",
    "pyemma.plots.plot_free_energy(all_data[:,0], all_data[:,1], avoid_zero_count=1)\n",
    "axis(extend)\n",
    "\n",
    "all_data=np.vstack(pca_HG317shell_ts)\n",
    "pyemma.plots.plot_free_energy(all_data[:,0], all_data[:,1], avoid_zero_count=1)\n",
    "axis(extend)\n",
    "\n",
    "all_data=np.vstack(pca_HG4_ts)\n",
    "pyemma.plots.plot_free_energy(all_data[:,0], all_data[:,1], avoid_zero_count=1)\n",
    "axis(extend)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you will see the contributions of each feat (or the most important feats) for each PCA dimension (PC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dist_PCA_correl = pca_joint.feature_PC_correlation\n",
    "\n",
    "n_argmax = 2\n",
    "for ii, icorr in enumerate(dist_PCA_correl.T):\n",
    "    print(\"For PCA %u\"%ii)\n",
    "    argmaxs = [ii for ii in np.abs(icorr).argsort()[::-1] if not np.isnan(icorr[ii])]\n",
    "    for art in argmaxs[:15]:\n",
    "        print(feats[0].describe()[art][9:12])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(pca_HG3_apo, open (\"FELS_JOINT/pca_HG3_apo.p\", \"wb\"))\n",
    "pickle.dump(pca_HG317_apo, open (\"FELS_JOINT/pca_HG317_apo.p\", \"wb\"))\n",
    "pickle.dump(pca_HG317shell_apo, open (\"FELS_JOINT/pca_HG317shell_apo.p\", \"wb\"))\n",
    "pickle.dump(pca_HG4_apo, open (\"FELS_JOINT/pca_HG4_apo.p\", \"wb\"))\n",
    "pickle.dump(pca_HG3_ts, open (\"FELS_JOINT/pca_HG3_ts.p\", \"wb\"))\n",
    "pickle.dump(pca_HG317_ts, open (\"FELS_JOINT/pca_HG317_ts.p\", \"wb\"))\n",
    "pickle.dump(pca_HG317shell_ts, open (\"FELS_JOINT/pca_HG317shell_ts.p\", \"wb\"))\n",
    "pickle.dump(pca_HG4_ts, open (\"FELS_JOINT/pca_HG4_ts.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tICA\n",
    "\n",
    "The biggest difference between PCA and tICA is the introduction of the lag time parameter. With this parameter we can ignore fast movements that are not important for the system like vibrations and side chain rotations. Is important to chose a propper lag time that reduces the number of dimensions that explains the variations in the MD's.\n",
    "\n",
    "To select a initial lag time, we use this code to sample different values and we select the one that explains the same variation in less dimensions (minimum in the plot)\n",
    "\n",
    "###### This part may take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute TICA on the combined data from all trajectories\n",
    "\n",
    "multi_tica=[]\n",
    "\n",
    "for i in [10,50,100,200,500,750,1000]:\n",
    "    tica_joint=pyemma.coordinates.tica(data=[t for t in joint_data if len(t)>1500],lag=i,stride=1)\n",
    "    multi_tica.append([i,[tica_joint.lag, tica_joint.ndim]])\n",
    "    del(tica_joint)\n",
    "    \n",
    "plt.plot([t[1][0] for t in multi_tica], [t[1][1]for t in multi_tica])\n",
    "plt.xlabel('lagtime')\n",
    "plt.ylabel('dimensions')\n",
    "plt.show()\n",
    "for tica in multi_tica:\n",
    "    print(tica) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "lag=200   # We add the lag time that we selected in the previous part\n",
    "tica_joint=pyemma.coordinates.tica(data=joint_data,lag=lag,kinetic_map=False,stride=1)\n",
    "#kmeans=pyemma.coordinates.cluster_kmeans(data=None,k=25,max_iter=100)\n",
    "#disc = pyemma.coordinates.discretizer(joint_data,transform=tica_joint,cluster=kmeans,stride=1)\n",
    "\n",
    "#We get the output from tica on the combined dataset\n",
    "Y_test = tica_joint.get_output()\n",
    "\n",
    "#We know divide the tica output to recover the tica object for each dataset, i.e. tica for WT, tica for Lovd1..\n",
    "\n",
    "tica_APO,tica_APOMG, tica_THM, tica_GCV, tica_THM_ATP, tica_GCV_ATP, tica_TMP_ADP, tica_GMP_ADP = np.split(Y_test, np.cumsum(list(map(len, trajfiles)))[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We now compute the free energy of the combined dataset and separated datasets\n",
    "\n",
    "dims = 0,1\n",
    "\n",
    "all_data=np.vstack(Y_test)\n",
    "pyemma.plots.plot_free_energy(all_data[:,dims[0]], all_data[:,dims[1]], avoid_zero_count=1)\n",
    "# extend=axis()\n",
    "\n",
    "all_data=np.vstack(tica_HG3_apo)\n",
    "pyemma.plots.plot_free_energy(all_data[:,0], all_data[:,1], avoid_zero_count=1)\n",
    "axis(extend)\n",
    "\n",
    "all_data=np.vstack(tica_HG317_apo)\n",
    "pyemma.plots.plot_free_energy(all_data[:,0], all_data[:,1], avoid_zero_count=1)\n",
    "axis(extend)\n",
    "\n",
    "all_data=np.vstack(tica_HG317shell_apo)\n",
    "pyemma.plots.plot_free_energy(all_data[:,0], all_data[:,1], avoid_zero_count=1)\n",
    "axis(extend)\n",
    "\n",
    "all_data=np.vstack(tica_HG_4apo)\n",
    "pyemma.plots.plot_free_energy(all_data[:,0], all_data[:,1], avoid_zero_count=1)\n",
    "axis(extend)\n",
    "\n",
    "all_data=np.vstack(tica_HG3_ts)\n",
    "pyemma.plots.plot_free_energy(all_data[:,0], all_data[:,1], avoid_zero_count=1)\n",
    "axis(extend)\n",
    "\n",
    "all_data=np.vstack(tica_HG317_ts)\n",
    "pyemma.plots.plot_free_energy(all_data[:,0], all_data[:,1], avoid_zero_count=1)\n",
    "axis(extend)\n",
    "\n",
    "all_data=np.vstack(tica_HG317shell_ts)\n",
    "pyemma.plots.plot_free_energy(all_data[:,0], all_data[:,1], avoid_zero_count=1)\n",
    "axis(extend)\n",
    "\n",
    "all_data=np.vstack(tica_HG4_ts)\n",
    "pyemma.plots.plot_free_energy(all_data[:,0], all_data[:,1], avoid_zero_count=1)\n",
    "axis(extend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dist_TICA_correl = tica_joint.feature_TIC_correlation\n",
    "\n",
    "n_argmax = 2\n",
    "for ii, icorr in enumerate(dist_TICA_correl.T):\n",
    "    print(\"For TICA %u\"%ii)\n",
    "    argmaxs = [ii for ii in np.abs(icorr).argsort()[::-1] if not np.isnan(icorr[ii])]\n",
    "    for art in argmaxs[:15]:\n",
    "        print(feats[0].describe()[art][9:12])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pca_HG3_apo, open (\"FELS_JOINT/pca_HG3_apo.p\", \"wb\"))\n",
    "pickle.dump(pca_HG317_apo, open (\"FELS_JOINT/pca_HG317_apo.p\", \"wb\"))\n",
    "pickle.dump(pca_HG317shell_apo, open (\"FELS_JOINT/pca_HG317shell_apo.p\", \"wb\"))\n",
    "pickle.dump(pca_HG4_apo, open (\"FELS_JOINT/pca_HG4_apo.p\", \"wb\"))\n",
    "pickle.dump(pca_HG3_ts, open (\"FELS_JOINT/pca_HG3_ts.p\", \"wb\"))\n",
    "pickle.dump(pca_HG317_ts, open (\"FELS_JOINT/pca_HG317_ts.p\", \"wb\"))\n",
    "pickle.dump(pca_HG317shell_ts, open (\"FELS_JOINT/pca_HG317shell_ts.p\", \"wb\"))\n",
    "pickle.dump(pca_HG4_ts, open (\"FELS_JOINT/pca_HG4_ts.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
